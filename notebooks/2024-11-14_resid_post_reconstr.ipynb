{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking a Jacobian SAE and using it to compute reconstruction metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-70m-deduped into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import transformer_lens\n",
    "from typing import Any\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import sae_lens\n",
    "\n",
    "model = transformer_lens.HookedTransformer.from_pretrained(\"pythia-70m-deduped\")\n",
    "sae = sae_lens.SAE.from_pretrained(\"pythia-70m-deduped-res-sm\", \"blocks.2.hook_resid_post\")[0]\n",
    "layer = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using two hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Never gonna give you up, never gonna let you down\"\n",
    "\n",
    "original_logits, original_ce_loss = model(\n",
    "    prompt, return_type=\"both\", loss_per_token=True\n",
    ")\n",
    "\n",
    "def reconstr_hook(activations: torch.Tensor, hook: Any):\n",
    "    original_device = activations.device\n",
    "    activations = activations.to(sae.device)\n",
    "\n",
    "    activations = sae.decode(sae.encode(activations)).to(activations.dtype)\n",
    "\n",
    "    return activations.to(original_device)\n",
    "\n",
    "reconstr_logits, reconstr_ce_loss = model.run_with_hooks(\n",
    "    prompt,\n",
    "    return_type=\"both\",\n",
    "    fwd_hooks=[(f\"blocks.{layer}.hook_resid_pre\", reconstr_hook)],\n",
    "    loss_per_token=True,\n",
    ")\n",
    "\n",
    "double_reconstr_logits, double_reconstr_ce_loss = model.run_with_hooks(\n",
    "    prompt,\n",
    "    return_type=\"both\",\n",
    "    fwd_hooks=[(f\"blocks.{layer}.hook_resid_pre\", reconstr_hook),\n",
    "               (f\"blocks.{layer}.hook_resid_post\", reconstr_hook)],\n",
    "    loss_per_token=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4.7383, device='mps:0', grad_fn=<MeanBackward0>),\n",
       " tensor(4.8325, device='mps:0', grad_fn=<MeanBackward0>),\n",
       " tensor(6.8677, device='mps:0', grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_ce_loss.mean(), reconstr_ce_loss.mean(), double_reconstr_ce_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4.8349, device='mps:0', grad_fn=<DivBackward0>),\n",
       " tensor(14.7052, device='mps:0', grad_fn=<DivBackward0>))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_logprobs = F.log_softmax(original_logits, dim=-1)\n",
    "reconstr_logprobs = F.log_softmax(reconstr_logits, dim=-1)\n",
    "double_reconstr_logprobs = F.log_softmax(double_reconstr_logits, dim=-1)\n",
    "\n",
    "(F.kl_div(reconstr_logprobs, original_logprobs, reduction=\"batchmean\", log_target=True),\n",
    " F.kl_div(double_reconstr_logprobs, original_logprobs, reduction=\"batchmean\", log_target=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rewriting a cache run to a hooks run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 512])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, cache = model.run_with_cache(\n",
    "    prompt,\n",
    "    prepend_bos=False,\n",
    "    names_filter=[f\"blocks.{layer}.hook_resid_pre\", f\"blocks.{layer}.hook_resid_post\"],\n",
    "    stop_at_layer=layer + 1,\n",
    ")\n",
    "\n",
    "resid_pre1 = cache[f\"blocks.{layer}.hook_resid_pre\"]\n",
    "resid_pre1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 512])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_device = resid_pre1.device\n",
    "acts = resid_pre1.to(sae.device)\n",
    "\n",
    "acts = sae.decode(sae.encode(acts)).to(acts.dtype)\n",
    "\n",
    "acts = acts.to(original_device)\n",
    "\n",
    "reid_post1 = model.blocks[layer](acts)\n",
    "reid_post1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 512])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache2 = {}\n",
    "def reconstr_and_cache_hook(activations: torch.Tensor, hook: Any):\n",
    "    cache2[hook.name] = activations\n",
    "    original_device = activations.device\n",
    "    activations = activations.to(sae.device)\n",
    "\n",
    "    activations = sae.decode(sae.encode(activations)).to(activations.dtype)\n",
    "\n",
    "    return activations.to(original_device)\n",
    "\n",
    "\n",
    "model.run_with_hooks(\n",
    "    prompt,\n",
    "    fwd_hooks=[(f\"blocks.{layer}.hook_resid_pre\", reconstr_and_cache_hook),\n",
    "               (f\"blocks.{layer}.hook_resid_post\", reconstr_and_cache_hook)],\n",
    "    stop_at_layer=layer + 1,\n",
    "    prepend_bos=False,\n",
    ")\n",
    "cache2[f\"blocks.{layer}.hook_resid_pre\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='mps:0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(resid_pre1 == cache2[f\"blocks.{layer}.hook_resid_pre\"]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False, device='mps:0')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cache[f\"blocks.{layer}.hook_resid_post\"] == cache2[f\"blocks.{layer}.hook_resid_post\"]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='mps:0')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(reid_post1 == cache2[f\"blocks.{layer}.hook_resid_post\"]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
