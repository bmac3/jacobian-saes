#!/usr/bin/env python3
# Downloads all artifacts from a wandb project into local storage on BluePebble

import argparse
from tqdm import tqdm
import wandb

# parse args
parser = argparse.ArgumentParser(
    description="Download all the artifacts from a wandb project"
)
parser.add_argument(
    "--path",
    "-p",
    type=str,
    default="lucyfarnik/pythia-410m-v2",
    help="Wandb path to the project",
)
args = parser.parse_args()

api = wandb.Api()

type_names = ["model", "log_feature_sparsity", "wandb-history"]

for type_name in type_names:
    colls = api.artifact_type(type_name=type_name, project=args.path).collections(per_page=500)

    # TODO maybe parallelize (though I don't think that would acc help much for the actual bottleneck)
    for coll in tqdm(colls, desc=f"Downloading {type_name} artifacts"):
        for artifact in coll.artifacts(per_page=500):
            artifact.download()


print("Downloaded all artifacts")
